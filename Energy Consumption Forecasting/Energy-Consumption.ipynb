{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Combine Energy Consumption Files\n",
    "# -------------------------------\n",
    "for num in range(0, 112):\n",
    "    df = pd.read_csv(r\"C:\\Users\\karim\\Desktop\\New folder\\daily_dataset\\block_\" + str(num) + \".csv\")\n",
    "    df = df[['day', 'LCLid', 'energy_sum']]  # Keep only relevant columns\n",
    "    df.reset_index()  # Reset index\n",
    "    df.to_csv(r\"C:\\Users\\karim\\Desktop\\New folder\\output\\hc_\" + str(num) + \".csv\")  # Save cleaned files\n",
    "\n",
    "# Combine all individual files into a single dataset\n",
    "fout = open(r\"C:\\Users\\karim\\Desktop\\New folder\\energy.csv\", \"a\")\n",
    "for line in open(r\"C:\\Users\\karim\\Desktop\\New folder\\output\\hc_0.csv\"):\n",
    "    fout.write(line)\n",
    "for num in range(0, 112):\n",
    "    f = open(r\"C:\\Users\\karim\\Desktop\\New folder\\output\\hc_\" + str(num) + \".csv\")\n",
    "    f.readline()  # Skip header for subsequent files\n",
    "    for line in f:\n",
    "        fout.write(line)\n",
    "    f.close()\n",
    "fout.close()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Load and Process Energy Data\n",
    "# -------------------------------\n",
    "energy = pd.read_csv(r\"C:\\Users\\karim\\Desktop\\New folder\\energy.csv\")\n",
    "housecount = energy.groupby('day')[['LCLid']].nunique()  # Count unique households per day\n",
    "energy = energy.groupby('day')[['energy_sum']].sum()  # Sum energy consumption per day\n",
    "energy = energy.merge(housecount, on='day')  # Add household count\n",
    "energy = energy.reset_index()  # Reset index\n",
    "\n",
    "# Add average energy consumption per household\n",
    "energy['avg_energy'] = energy['energy_sum'] / energy['LCLid']\n",
    "\n",
    "# Convert 'day' column to datetime\n",
    "energy['day'] = pd.to_datetime(energy['day'], format='%Y-%m-%d').dt.date\n",
    "\n",
    "# Print data range\n",
    "print(\"Starting Point of Data at Day Level:\", min(energy['day']))\n",
    "print(\"Ending Point of Data at Day Level:\", max(energy['day']))\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Load and Process Weather Data\n",
    "# -------------------------------\n",
    "weather = pd.read_csv(r\"C:\\Users\\karim\\Desktop\\New folder\\weather_daily_darksky.csv\")\n",
    "weather['day'] = pd.to_datetime(weather['time']).dt.date  # Convert timestamp to date\n",
    "weather = weather.dropna()  # Drop rows with missing values\n",
    "\n",
    "# Keep relevant columns\n",
    "weather = weather[['temperatureMax', 'humidity', 'windSpeed', 'cloudCover', 'visibility', 'day']]\n",
    "\n",
    "# Merge energy and weather data\n",
    "weather_energy = energy.merge(weather, on='day')\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Visualize Relationships\n",
    "# -------------------------------\n",
    "fig, ax1 = plt.subplots(figsize=(20, 5))\n",
    "ax1.plot(weather_energy['day'], weather_energy['temperatureMax'], color='tab:orange', label='Temperature Max')\n",
    "ax1.plot(weather_energy['day'], weather_energy['avg_energy'], color='tab:blue', label='Average Energy')\n",
    "ax1.set_ylabel('Temperature/Energy')\n",
    "plt.legend()\n",
    "plt.title('Energy Consumption and Temperature')\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Scaling & Clustering for Weather Conditions\n",
    "# -------------------------------\n",
    "scaler = MinMaxScaler()\n",
    "weather_scaled = scaler.fit_transform(weather_energy[['temperatureMax', 'humidity', 'windSpeed']])\n",
    "\n",
    "# Elbow curve to determine optimal clusters\n",
    "Nc = range(1, 20)\n",
    "kmeans = [KMeans(n_clusters=i) for i in Nc]\n",
    "scores = [kmeans[i].fit(weather_scaled).score(weather_scaled) for i in range(len(kmeans))]\n",
    "plt.plot(Nc, scores)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()\n",
    "\n",
    "# Fit KMeans with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, max_iter=600)\n",
    "kmeans.fit(weather_scaled)\n",
    "weather_energy['weather_cluster'] = kmeans.labels_\n",
    "\n",
    "# -------------------------------\n",
    "# Step 6: Add Holiday Indicator\n",
    "# -------------------------------\n",
    "holiday = pd.read_csv(r\"C:\\Users\\karim\\Desktop\\New folder\\uk_bank_holidays.csv\")\n",
    "holiday['Bank holidays'] = pd.to_datetime(holiday['Bank holidays'], format='%Y-%m-%d').dt.date\n",
    "weather_energy = weather_energy.merge(holiday, left_on='day', right_on='Bank holidays', how='left')\n",
    "weather_energy['holiday_ind'] = np.where(weather_energy['Bank holidays'].isna(), 0, 1)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 7: Train-Test Split\n",
    "# -------------------------------\n",
    "weather_energy.set_index(['day'], inplace=True)\n",
    "model_data = weather_energy[['avg_energy', 'weather_cluster', 'holiday_ind']]\n",
    "\n",
    "# 70-30 train-test split\n",
    "train = model_data.iloc[0:(len(model_data) - 30)]\n",
    "test = model_data.iloc[len(train):]\n",
    "\n",
    "# -------------------------------\n",
    "# Step 8: Test for Stationarity\n",
    "# -------------------------------\n",
    "t = sm.tsa.adfuller(train['avg_energy'], autolag='AIC')\n",
    "print(pd.Series(t[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used']))\n",
    "\n",
    "# -------------------------------\n",
    "# Step 9: Build and Evaluate SARIMAX Model\n",
    "# -------------------------------\n",
    "endog = train['avg_energy']\n",
    "exog = train[['weather_cluster', 'holiday_ind']]\n",
    "mod = SARIMAX(endog=endog, exog=exog, order=(7, 1, 1), seasonal_order=(1, 1, 0, 12), trend='c')\n",
    "model_fit = mod.fit()\n",
    "\n",
    "# Predictions\n",
    "predict = model_fit.predict(start=len(train), end=len(train)+len(test)-1, exog=test[['weather_cluster', 'holiday_ind']])\n",
    "test['predicted'] = predict.values\n",
    "\n",
    "# Calculate Errors\n",
    "test['residual'] = abs(test['avg_energy'] - test['predicted'])\n",
    "MAE = test['residual'].mean()\n",
    "MAPE = (test['residual'] / test['avg_energy']).mean() * 100\n",
    "print(\"MAE:\", MAE)\n",
    "print(\"MAPE:\", MAPE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
